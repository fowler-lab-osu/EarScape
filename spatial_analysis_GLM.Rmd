---
title: "Spatial Analysis GLM"
author: "Michelle Bang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Part 0: Loading all of my files and functions

```{r}
source("Helper_Code/xml_to_coordinates.R")
source("Helper_Code/coordinates_to_xbins.R")
source("Helper_Code/xml_to_coord_edited.R")

library(ggplot2)
library(tidyverse)
library(ggpubr)
```

```{r}
library(qvalue)
library(scales)
```

```{r}
#Function to change xml to coordinates depending on the file type. 
xml_to_coord <- function(input_data_path){
  #print(input_data_path)
  if (grepl("\\_inference.xml", input_data_path)){
    xml_to_coordinates2(input_data_path)
  } else{
    xml_to_coordinates(input_data_path)
  }
}
```

```{r}
#Getting the all the .xml files. Divided into folders depending on the allele.
cross <- "ear"

if(cross=="ear"){
  list_alleles <- list.dirs("./SpatialAnalysis_Alleles_58/Ear_Crosses", full.names = FALSE, recursive = FALSE)
}
if(cross=="pollen"){
  list_alleles <- list.dirs("./SpatialAnalysis_Alleles_58/Pollen_Crosses", full.names = FALSE, recursive = FALSE)
}
```

```{r}
#Creating a list that is separated by allele/folder.
filenames = vector(mode='list', length= length(list_alleles))
```

```{r}
#Making each list element hold a list of 3 elements. 
for (i in 1:length(list_alleles)){
  filenames[[i]] = vector(mode='list', length= 3)
}
```

```{r}
for (i in 1:length(list_alleles)){
  #Getting name of allele
  filenames[[i]][[1]] <- list_alleles[[i]] 
  #Getting path to observation.
  if(cross=="ear"){
    filenames[[i]][[2]] = list.files(paste0("./SpatialAnalysis_Alleles_58/Ear_Crosses/", list_alleles[[i]]), pattern="*.xml", full.names=TRUE) 
  }
  if(cross=="pollen"){
    filenames[[i]][[2]] = list.files(paste0("./SpatialAnalysis_Alleles_58/Pollen_Crosses/", list_alleles[[i]]), pattern="*.xml", full.names=TRUE) 
  }
  #Extracting the name of observation.
  filenames[[i]][[3]] = as.list(basename(filenames[[i]][[2]])) 
}

d <- 0
for(i in 1:58){

d <- d + length(filenames[[i]][[3]])

}
```


```{r}
#Create data frame for summary statistics with Fisher combo test and including transmission rates.
sumStats = data.frame(matrix(nrow = length(filenames), ncol = 14)) 
colnames(sumStats) <- c("Allele", "Increasing Linear", "Decreasing Linear", "Quadratic", "Transmission Rate")
sumStats[1] = list_alleles
```



```{r}
#Create mega dataframe to contain information for all 25 alleles.
megaDf = data.frame()
anova_comp_full = data.frame()
```

```{r}
#Create data frame for summary statistics regarding coefficients. 
stat_sum = data.frame(matrix(nrow = length(filenames), ncol = 7)) 
colnames(stat_sum) <- c("Allele", "Lin Coef", "Lin SE", "Lin Var", "Quad Coef", "Quad SE", "Quad Var")
stat_sum[1] = list_alleles
```


```{r}
#Main code looped for all alleles in folder. 

for (n in 1:length(filenames)){
  print(filenames[[n]][[2]])
  coords = lapply(filenames[[n]][[2]], xml_to_coord)

  #Removes faulty xml from the files. 

  sequence = rev(seq(1:length(coords)))

#Checks if there will be an error when coordinates_to_xbins runs. If there is, it removes it from filenames 
for (i in sequence) {
  if (nrow(coords[[i]]) == 0)  {
    filenames[[n]][[2]] = filenames[[n]][[2]][-i]
    filenames[[n]][[3]] = filenames[[n]][[3]][-i]
  }
}

#The 0 observation issue is caused by files that don't use 1 and 2 as their marker numbers which is a requirement for xml_to_coordinates
bin_data = lapply(coords, function(x) {coordinates_to_xbins(x,16)} )

sequence = rev(seq(1:length(bin_data)))

#Removes the files that break the glm, namely the ears with only one kind of kernel allele. At most removes the cases with very few WT or GFP which are by definition odd ears. 
for (i in sequence) {
  sumWT = sum(bin_data[[i]]$WT)
  sumGFP = sum(bin_data[[i]]$GFP)
    if ((sumWT < 5) | (sumGFP < 5)) {
      bin_data = bin_data[-i]
      filenames[[n]][[2]] = filenames[[n]][[2]][-i]
      filenames[[n]][[3]] = filenames[[n]][[3]][-i]
    }
}

#The 0 observation issue is caused by files that don't use 1 and 2 as their marker numbers which is a requirement for xml_to_coordinates
full_data = lapply(coords, function(x) {coordinates_to_xbins(x,1)} )

sequence = rev(seq(1:length(full_data)))

#Removes the files that break the glm, namely the ears with only one kind of kernel allele. At most removes the cases with very few WT or GFP which are by definition odd ears. 

for (i in sequence) {
  sumWT = sum(full_data[[i]]$WT)
  sumGFP = sum(full_data[[i]]$GFP)
    if ((sumWT < 5) | (sumGFP < 5)) {
      full_data = full_data[-i]
    }
}


TransmissionRateAllBins <- c()
for (i in 1:length(filenames[[n]][[2]])) {
  TransmissionRateAllBins  <- append(TransmissionRateAllBins , full_data[[i]]$GFP/(full_data[[i]]$GFP + full_data[[i]]$WT))
}



#Start chopping off the ends
sequence = seq(1,length(bin_data))

#Creating an empty list
bin_ed = list()

for (i in sequence) {
    bin_ed[[i]] = data.frame("bins" = bin_data[[i]]$bins[2:15], "WT" = bin_data[[i]]$WT[2:15] , "GFP" = bin_data[[i]]$GFP[2:15])
}


alleleGFP <- sum(do.call(rbind,bin_ed)$GFP)
alleleWT <- sum(do.call(rbind,bin_ed)$WT)

#Turn the data into a glm
ends_glm_data = lapply(bin_ed, function(x) {glm(cbind(GFP,WT) ~ bins,family = quasibinomial(link = "logit"), data = x)})

#Extract the p values
ends_pv_data = lapply(ends_glm_data, function(x) {(summary(x)$coefficients)})
ends_p_data = lapply(ends_pv_data, function(x) {x[8]})


#lapply(ends_glm_data, function(x) {print(summary(x))})

t_stats = lapply(ends_pv_data, function(x) {x[6]})


lower_tail_pvals = lapply(t_stats, function(x) {pt(x, df=12, lower.tail = TRUE)}) #probs P[<t]  
upper_tail_pvals = lapply(t_stats, function(x) {pt(x, df=12, lower.tail = FALSE)}) #probs P[>=t]  

linearCoeffMean = mean(unlist(lapply(ends_pv_data, function(x){x['bins','Estimate']})))
linearCoeffVar = var(unlist(lapply(ends_pv_data, function(x){x['bins','Estimate']})))


#Comment this out to look at the non adjusted values, you can swap the method by changing 'method = fdr'
adj_p_data = p.adjust(ends_p_data,method = "fdr")

adj_p_df <- data.frame(matrix(unlist(adj_p_data), nrow=length(adj_p_data), byrow=T))
names(adj_p_df)[names(adj_p_df) == colnames(adj_p_df[1])] = "adj_p_value"

ends_p_df <- data.frame(matrix(unlist(ends_p_data), nrow=length(ends_p_data), byrow=T))
names(ends_p_df)[names(ends_p_df) == colnames(ends_p_df[1])] = "p_value"

titleDf <- data.frame(unlist(filenames[[n]][[3]]))
colnames(titleDf) <- "Name"


endsfullDf = cbind(titleDf, ends_p_df)
endsfullDf <- cbind(endsfullDf, adj_p_df)

endsfullDf <- endsfullDf %>%
  mutate(allele = filenames[[n]][[1]])


fisher_upper <- -2 * sum(log(unlist(upper_tail_pvals)))
linear_fisher_upper_p <- pchisq(fisher_upper, 2*length(unlist(upper_tail_pvals)), lower.tail = FALSE, log.p = FALSE)
#print("linear fish upper:")
#print(linear_fisher_upper_p)
sumStats[n,2] =   linear_fisher_upper_p


fisher_lower <- -2 * sum( log(unlist(lower_tail_pvals)))
linear_fisher_lower_p <- pchisq(fisher_lower, 2*length(unlist(lower_tail_pvals)), lower.tail = FALSE, log.p = FALSE)
#print("linear fish lower:")
#print(linear_fisher_lower_p)
sumStats[n,3] =   linear_fisher_lower_p


#ANOVA Testing for quadratic term
#First part of set up should be the same as GLM with ends chopped off.

bins_squared_ends = bin_ed
bin_sq_data_ends = bin_ed

sequence = seq(1, length(bin_ed))
sequence2  = seq(1, 14)

for (i in sequence) {
  for (j in sequence2) {
  bins_squared_ends[[i]]$bins[j] = (bin_sq_data_ends[[i]]$bins[j])^2
  }
  bin_sq_data_ends[[i]] = data.frame(bin_sq_data_ends[[i]],bins_squared_ends[[i]]$bins)
}


#Turn the data into a glm
#If this breaks just double check how R is naming the bin_squared column of bin_data and replace "bins_squared..i...bins" with that
sq_glm_data_ends = lapply(bin_sq_data_ends, function(x) {glm(cbind(GFP,WT) ~ bins + bins_squared_ends..i...bins,family = quasibinomial(link = "logit"), data = x)})

#Creating null model
null_ends_model <- lapply(bin_ed, function(x) {glm(cbind(GFP,WT) ~ 1,family = quasibinomial(link = "logit"), data = x)})


#Setting up empty list
anova_ends_data <- vector(length = length(bin_ed))

for (i in 1:length(bin_ed)){
  anova_ends_data[i] <- anova(null_ends_model[[i]], sq_glm_data_ends[[i]], test = "F")$"Pr(>F)"[2]
}

anova_ends_df <- as.data.frame(anova_ends_data)
row.names(anova_ends_df) <- 1:length(bin_ed)
adj_anova = p.adjust(anova_ends_data, method = "fdr")
colnames(anova_ends_df)[1] = "p_value_sq"
#Uncomment for when you want to add column for names.
#anova_ends_df <- cbind(anova_ends_df, titleDf)
#colnames(anova_ends_df)[2] = "name"
anova_ends_df <- cbind(anova_ends_df, adj_anova)
colnames(anova_ends_df)[2] = "adj_p_value_sq"


#print("Quad BIN COEFFS")
quad_glm_summary = lapply(sq_glm_data_ends, function(x) {(summary(x)$coefficients)})
#print(quad_glm_summary)
quadCoeffMean = mean(unlist(lapply(quad_glm_summary, function(x){x['bins_squared_ends..i...bins','Estimate']})))
quadCoeffVar = var(unlist(lapply(quad_glm_summary, function(x){x['bins_squared_ends..i...bins','Estimate']})))
#print("Quad Coeff Mean")
#print(quadCoeffMean)
#print("Quad Coeff Variance")
#print(quadCoeffVar)


fisherStat <- -2 * sum( log(unlist(anova_ends_data)))
quad_fisher_p <- pchisq(fisherStat, 2*length(unlist(anova_ends_data)), lower.tail = FALSE,
            log.p = FALSE)
#print("Quadratic fish: ")
#print(quad_fisher_p)
sumStats[n,4] = quad_fisher_p

sumStats[n,5] = alleleGFP / (alleleGFP+alleleWT) #Transmission Rate for allele using kernel counts only from included bins


endsfullDf <- cbind(endsfullDf, anova_ends_df)

#Saving all data as .tsv
megaDf <- rbind(megaDf, endsfullDf)
coef_ends_glm <- c()
for(k in 1:length(ends_glm_data)){
  coef_ends_glm <- append(coef_ends_glm, ends_glm_data[[k]]$coefficients[["bins"]])
}
stat_sum[n,2] = mean(coef_ends_glm) 

se_ends <- c()
for(k in 1:length(ends_glm_data)){
  se_ends <- append(se_ends, summary(ends_glm_data[[k]])$coefficients[, 2][["bins"]])
}
se_ends_new <- se_ends^2
stat_sum[n,3] = sqrt(sum(se_ends_new)/length(ends_glm_data)^2) 

#var_ends <- c()
#just take the variance of the coefficients
#for(k in 1:length(ends_glm_data)){
#  var_ends <- append(var_ends, vcov(ends_glm_data[[k]])[2,2])
#}
stat_sum[n,4] = var(coef_ends_glm)

#stat_sum[n,4] = sum(var_ends)/length(ends_glm_data)^2 

coef_ends_sq_glm <- c()

for(k in 1:length(sq_glm_data_ends)){
  coef_ends_sq_glm <- append(coef_ends_sq_glm, sq_glm_data_ends[[k]]$coefficients[["bins_squared_ends..i...bins"]])
}
stat_sum[n,5] = mean(coef_ends_sq_glm)

se_sq_ends <- c()
for(k in 1:length(sq_glm_data_ends)){
  se_sq_ends <- append(se_sq_ends, summary(sq_glm_data_ends[[k]])$coefficients[, 2][["bins"]])
}
se_sq_ends_new <- se_sq_ends^2
stat_sum[n,6] = sqrt(sum(se_sq_ends_new)/length(sq_glm_data_ends)^2) 


#var_sq_ends <- c()
#for(k in 1:length(sq_glm_data_ends)){
#  var_sq_ends <- append(var_sq_ends, vcov(sq_glm_data_ends[[k]])[2,2])
#}
#stat_sum[n,7] = sum(var_sq_ends)/length(sq_glm_data_ends)^2
stat_sum[n,7] = var(coef_ends_sq_glm)

#ANOVA to test between linear model and the quadratic model
#Setting up empty list
anova_comparison <- vector(length = length(bin_ed))

for (i in 1:length(bin_ed)){
  anova_comparison[i] <- anova(ends_glm_data[[i]], sq_glm_data_ends[[i]], test = "F")$"Pr(>F)"[2]
}

anova_comp_df <- as.data.frame(anova_comparison)
row.names(anova_comp_df) <- 1:length(bin_ed)
adj_anova_comp = p.adjust(anova_comparison, method = "fdr")
colnames(anova_comp_df)[1] = "p_value"
anova_comp_df <- cbind(anova_comp_df, adj_anova_comp)
colnames(anova_comp_df)[2] = "adj_p_value"
anova_comp_df <- anova_comp_df %>%
  mutate(allele = filenames[[n]][[1]])

anova_comp_full <- rbind(anova_comp_full, anova_comp_df)

#Choosing only one p-value for pi0est
pi0est_p_vals <- data.frame(matrix(nrow = length(bin_ed), ncol = 1)) 
best_df <- data.frame(matrix(nrow = length(bin_ed), ncol = 8))
colnames(best_df) <- c("Allele", "Name", "P_Value", "Model", "Adj_P_Value", "Lin_Coef", "Quad_Coef", "Inc_Dec")
best_df[1] = filenames[[n]][[1]]
best_df[2] = titleDf

quad_count = 0
lin_count = 0

for (i in 1:length(bin_ed)) {
  if (anova_comp_df[[1]][[i]] > .1) {
    pi0est_p_vals[[1]][[i]] = ends_p_df[[1]][[i]]
    best_df[[3]][[i]] = ends_p_df[[1]][[i]]
    best_df[[4]][[i]] = "L"
    #add line about choosing adj pvalue for quad or lin
    lin_count = lin_count + 1
    #getting coef
    best_df[[6]][[i]] = coef_ends_glm[[i]]
    best_df[[7]][[i]] = "NA"
  } else {
    pi0est_p_vals[[1]][[i]] = anova_ends_df[[1]][[i]]
    best_df[[3]][[i]] = anova_ends_df[[1]][[i]]
    best_df[[4]][[i]] = "Q"
    #add line about choosing adj pvalue for quad or lin
    quad_count = quad_count + 1
    #getting coef
    best_df[[6]][[i]] = coef_ends_glm[[i]]
    best_df[[7]][[i]] = coef_ends_sq_glm[[i]]
  }
}

min_p = min(unlist(pi0est_p_vals)) + .05

#prop of adj pvalue below .1
adj_p_comp = p.adjust(unlist(pi0est_p_vals), method = "fdr")
adj_p_comp_df <- data.frame(matrix(unlist(adj_p_comp), nrow=length(adj_p_comp), byrow=T))
names(adj_p_comp_df)[names(adj_p_comp_df) == colnames(adj_p_comp_df[1])] = "adj_p_value"

best_df[[5]] = adj_p_comp

adj_cnt <- adj_p_comp_df %>%
  filter(adj_p_value < .1) %>%
  summarize(count = n())

adj_l_cnt <- best_df %>%
  filter(Adj_P_Value < .1, Model == "L") %>%
  summarize(count = n())

adj_q_cnt <- best_df %>%
  filter(Adj_P_Value < .1, Model == "Q") %>%
  summarize(count = n())

}

```



```{r}
#Creating table for mean transmission rate and observation count for each allele. 
mean_count <- megaDf %>%
  group_by(allele) %>%
  summarize(mean_rate = mean(TransmissionRateAllBins),
            count = n()) %>%
  arrange(desc(mean_rate))

sumStats <- merge(x = mean_count, sumStats, by.x="allele", by.y="Allele")
colnames(sumStats)[colnames(sumStats) == 'allele'] <- 'Allele'
colnames(sumStats)[colnames(sumStats) == 'count'] <- 'Count'

```

```{r}
sumStats <- sumStats[,c("Allele","Count","Increasing Linear", "Decreasing Linear", "Quadratic", "Transmission Rate")]
write.table(sumStats, file = paste("stat_sum_fisher_",cross,".tsv",sep=""), sep = "\t", row.names=FALSE)
```

```{r}
print("done")
```